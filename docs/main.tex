\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

\usepackage{caratula}
\usepackage{tpalgo3}

\usepackage{graphicx}
\usepackage{dirtytalk}
\usepackage{enumerate}

\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}

\usepackage{float}
\usepackage{geometry}
\usepackage{fixltx2e}
\usepackage{wrapfig}
\usepackage{cite}
\usepackage{dsfont}
\usepackage{float}
\usepackage[space]{grffile}

\geometry{
 a4paper,
 total={210mm,297mm},
 left=30mm,
 right=30mm,
 top=30mm,
 bottom=30mm,
 }
 
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corolario}[theorem]
\newtheorem{lemma}{Lema}[theorem]
 
\theoremstyle{definition}
\newtheorem{definition}{Definición}[section]
 
\theoremstyle{remark}
\newtheorem*{remark}{Observación}
 
\begin{document}
% Estos comandos deben ir antes del \maketitle
\materia{Algorítmos y Estructuras de Datos III} % obligatorio

\titulo{Trabajo Práctico 2}
\subtitulo{}
\grupo{}

\integrante{Bayardo Julián}{850/13}{julian@bayardo.com.ar} % obligatorio
\integrante{Cuneo Christian}{755/13}{chriscuneo93@gmail.com} % obligatorio 
\integrante{Frassia Fernando}{340/13}{ferfrassia@gmail.com} % obligatorio 
\integrante{Gambaccini Ezequiel}{715/13}{ezequiel.gambaccini@gmail.com} % obligatorio 
 
\maketitle

\pagebreak

\tableofcontents

\pagebreak


\section{Problema 1}

\subsection{Resolución}

Para la resolución de este ejercicio, nos basamos en la metodología clásica para resolver problemas de programación dinámica. Para facilitar la terminología, de aquí en adelante nos referiremos a los pisos como nodos y a los portales como aristas, ya que es la forma más natural de modelar el problema utilizando digrafos. Primero, nótese que la condición de que los portales sólo pueden conectar hacia pisos más altos nos permite tomar un orden a los nodos, donde ponemos uno antes del otro cuando el número de piso es más bajo. Observemos, además, que este orden tiene una propiedad particular: todas las aristas van de un nodo más chico hacia uno más alto.

%% TODO: IMAGEN!!

Supongamos, entonces, que tenemos tan sólo 1 nodo. En este caso, el único camino posible es el camino vacío, y por lo tanto el mismo es el máximo. Por otro lado, si tenemos $n + 1$ nodos, y poseemos las longitudes $L_i$ de los caminos máximos que conectan al piso inicial con cada uno de los $n$ nodos anteriores, observemos que la longitud del camino máximo hasta el nodo $n + 1$ es exactamente:

$$L_{n + 1} = max\{L_k + 1 : k \in \mathbb{N}, k \leq n, \text{el nodo } k \text{ está conectado con } n + 1 \text{ y existe camino desde } 0 \text{ hasta } k\}$$

Es decir, la longitud del camino máximo que conecta al nodo inicial con el nodo $n + 1$ es la longitud del camino máximo que conecta al nodo inicial con algún nodo anterior al mismo que esté conectado con $n + 1$, sumándole 1 (por la arista adicional que tendríamos que utilizar). Observemos que esto es posible únicamente por la condición del orden que mencionamos anteriormente, ya que en general la condición de optimalidad no se cumple para camino máximo, como vimos en la teórica.

\begin{lemma}
El camino máximo en el sentido descripto cumple con el principio de optimalidad.
\end{lemma}

\begin{proof}
Sea $C$ un camino de longitud máxima que une al nodo inicial con el nodo $n$, y supongamos que hay algún fragmento del camino que no es máximo, llamémosle a este fragmento $H$. Entonces, existe algún fragmento $J$ que une a los mismos nodos que $H$ y cumple que $|J| > |H| \iff |J| - |H| > 0$. Tomemos entonces al fragmento $C'$ como el que resulta de reemplazar en $C$ al fragmento $H$ por el fragmento $J$, entonces:

$$|C'| = |C| - |H| + |J| > |C|$$

Por lo tanto $C'$ es un camino con longitud mayor a $C$. Absurdo, pues $C$ era un camino de longitud máxima.
\end{proof}

En términos de la programación, elegimos utilizar la versión iterativa bottom up del algoritmo, donde básicamente la idea es recorrer un nodo y actualizar los vecinos, de forma similar al recorrido de un bfs: dado un nodo $i$, recorremos todos los posibles nodos a los que pueda tener un portal $j \in \{i + 1, .., n\}$, y si estamos conectados intentamos actualizar la distancia máxima hasta ese nodo. De cualquier forma, cabe destacar que sólo los nodos $i$ que sean alcanzables desde el comienzo deberían ser actualizados, ya que si no podríamos actualizar de forma errónea la distancia. El pseudocódigo está en el algoritmo \ref{alg:ex1}. %% TODO: ejemplo

\begin{definition}
Decimos que un piso es alcanzable cuando existe un camino desde el piso inicial hasta él.
\end{definition}

\begin{lemma}
Los nodos no alcanzables no alteran el camino máximo desde 0 a n.
\end{lemma}

\begin{proof}
Supongamos que un nodo no alcanzable sí altera el camino máximo entre los nodos 0 y n. Entonces, el nodo no alcanzable debe pertenecer al mismo. Absurdo, pues si pertenece al camino máximo entonces es alcanzable a través del sub-camino que lo une con 0.
\end{proof}

\begin{lemma}
Al comenzar la $i$-ésima iteración del ciclo externo, si el nodo $i$ es alcanzable, $best[i]$ tiene la longitud del camino más largo de $0$ a $i$.
\end{lemma}

\begin{proof}
Sea n la cantidad de pisos e $i$ el número de piso, tal que $0 \leq i < n$. \\
Por inducción en $i$. \\

Cuando $i = 0$, al iniciar la primera iteración, $best[0] = 0$. Esto es lo esperable, dado que por definición: el camino que comienza en un nodo y termina en sí mismo tiene longitud 0. \\

Luego, siendo $i > 0$, supongamos que el lema vale para todo $0 \leq k < i$, estando $k$ conectado con $i$. Esto significa que para todo nodo $k$, al comenzar la $k$-ésima iteración, el algoritmo llevaba guardado en $best[k]$ la longitud del camino máximo de $0$ a $k$ y luego del segundo ciclo los valores de todos los vecinos de $k$ fueron actualizados tomando el máximo entre el valor ya guardado y $best[k]+1$ (por utilizar la arista de $k$ a su vecino). Como dijimos que $i$ es vecino de $k$ y para cada $k$ estamos guardando en $best[i]$ el valor máximo entre el ya guardado y $best[k]+1$, en particular, al terminar de iterar por los $k$ nodos, obtuvimos el máximo entre todos los $best[k]+1$ en $best[i]$. Finalmente, podemos asegurar que ésta es la longitud máxima de $0$ a $i$ porque debe ser el máximo de todos los caminos que comienzan en 0 y llegan a él; y, por la condición de orden que mencionamos anteriormente en la demostración, todos estos caminos pasan únicamente por nodos inferiores a él y hemos recorrido todos.
\end{proof}

Finalmente, dado que el último nodo es alcanzable por definición del problema, por los lemas \textbf{1.0.2, 1.0.3}, sabemos que al retornar $best[floors-1]$ estamos devolviendo la longitud de un camino máximo del primer nodo al último.

\begin{algorithm}[h!]
\caption{Algoritmo de programación dinámica bottom up para el ejercicio 1. $n$ es la cantidad de pisos.\label{alg:ex1}}

\begin{algorithmic}[h!]
\Procedure{maximizePath}{floors: int, adyacencia: matriz de adyacencia del grafo}
\State best $\gets [0] * floors$ \Comment $O(n)$
\State reachable $\gets [false] * floors$ \Comment $O(n)$
\State reachable[0] $\gets true$ \Comment $O(1)$
\For{i in 0...floors - 1} \Comment $O(n^2)$
    \If{!reachable[i]} \Comment $O(1)$
        \State continue \Comment $O(1)$
    \EndIf
    
    \For{j in i...floors} \Comment $O(n)$
        \If{adyacencia[i][j]} \Comment $O(1)$
            \State best[j] $\gets$ max(best[j], best[i] + 1) \Comment $O(1)$
            \State reachable[j] $\gets$ true \Comment $O(1)$
        \EndIf    
    \EndFor
\EndFor
\State return best[floors-1] \Comment $O(1)$
\EndProcedure\\
\end{algorithmic}
\end{algorithm}

\subsection{Experimentación}

Como el algoritmo descripto es el único utilizado en la resolución del problema, y como pueden apreciarse las complejidades de las operaciones en el pseudocódigo del algoritmo \ref{alg:ex1}, lo único que queda por analizar son los dos ciclos que contiene y determinar los mejores y peores casos.

Se puede ver que el algoritmo contiene un ciclo principal, que siempre realiza $n$ iteraciones; dentro de él se tiene un condicional y un ciclo interno, y éste último se ejecutará en caso de no cumplirse la guarda del condicional previo. Dado que el ciclo principal se ejecuta siempre $n$ veces, centraremos el análisis en el ciclo secundario, veremos en qué casos se realiza y cómo afecta la complejidad en cada caso.

En peor caso, el ciclo secundario toma $n$ iteraciones y se realiza para cada iteración del ciclo principal. Esto es sucede cuando cada piso está conectado a todos los pisos más altos que él, porque para cada iteración del ciclo principal la guarda del condicional no se cumple (dado que el primer piso siempre va a poder alcanzar al piso actual), con lo cuál se ejecuta el ciclo secundario. Éste itera desde el próximo piso al actual hasta el último piso, lo cuál nos permite acotar por $n$ cantidad de iteraciones y dejando así la complejidad en peor caso como $O(n^2)$.

%% TODO: imagen del mejor y peor caso

Por otro lado, el mejor caso debería minimizar la cantidad de ejecuciones del ciclo secundario. Notemos que esto sucede cuando el único portal existente es el que va del primer piso al último piso, ya que esto implicaría que todos los pisos intermedios no serían alcanzables, forzando la guarda del if a saltear la iteración. Cuando esto sucede, las únicas iteraciones que realizaremos serán la primera (porque el nodo inicial es alcanzable trivialmente) y la última (porque el nodo final es alcanzable a través del único portal que conecta al inicial con el mismo). En la primera iteración, la guarda del if no se cumple y el ciclo en cuestión itera desde el piso 1 hasta el último, tomando $O(n)$ pasos. Por último, en la última iteración no se cumple la guarda del condicional pero dado que se trata del último piso tampoco se cumple la guarda del ciclo y por eso éste no corre. Habiendo dicho esto, podemos ver que el ciclo principal toma $n$ iteraciones, y cada una tiene complejidad $O(1)$ excepto la primera que es $O(n)$, por ende este caso toma $O(n)$.

En la práctica, los experimentos realizados nos permitieron comprobar que efectivamente la complejidad es como decíamos. La figura \ref{grf:ex1} muestra los resultados, y observemos que en ambos casos se termina convergiendo hacia constantes cuando dividimos por la complejidad esperada, con grandes variaciones para las instancias pequeñas, como era de esperarse. 

\begin{figure}[h!]
\centering
\includegraphics[width=10cm]{ex1}
\caption{El estadístico que tomamos es la media alfa podada de 100 corridas con $\alpha = 0.10$, que nos permite evitar algunos outliers. En ambos casos estamos graficando a las funciones sobre las complejidades esperadas. \label{grf:ex1}}
\end{figure}

\section{Problema 2}

\subsection{Resolución}

A priori, leer el enunciado del problema deja claro que la solución debe involucrar tomar el camino mínimo que conecte a la posición inicial con la posición final (el aula). El primer modelo al que llegamos involucraba tener 1 nodo por cada posición que tuviese un portal, y conectar cada uno de estos nodos con los otros que estén en el mismo piso (tomando como peso la cantidad de segundos que tardaríamos en recorrer el trayecto) y con los nodos a los que un portal pueda llevarlo (poniéndole peso 2 a cada arista, que simboliza una vez más la cantidad de tiempo). Con este modelo, queda claro que el problema del enunciado se traduce en calcular el camino mínimo que une a la posición inicial con el aula de algoritmos. Sin embargo, un análisis rápido de complejidad temporal muestra que este modelado no permite una solución que esté cumpla el enunciado utilizando los algoritmos que vimos en la clase, y por lo tanto rápidamente lo descartamos.

Encontramos, entonces, otro modelo posible: crear un nodo por cada posición posible (de esta forma tendríamos $NL$ nodos) y conectar todos los que estén en el mismo piso con peso 1 en las aristas, simbolizando que tardamos 1 segundo en movernos de una posición a otra; además, si hay un portal que conecta una posición con otra, agregamos un "nodo fantasma" en el medio, y conectamos el nodo a los dos extremos del portal con peso 1. Esta idea del "nodo fantasma" es para solucionar el p

De esta forma, tenemos exactamente $NL + P$ nodos (uno por posición y uno por portal) y un total de $N (L-1) + 2P$ aristas. Observemos que en este nuevo grafo, el hecho de tener pesos uniformes nos permite calcular el camino mínimo utilizando BFS como vimos en la teórica; dado que la complejidad temporal de BFS es $O(m + n)$, tenemos que en particular para este grafo se convierte en $O(NL + P + N (L-1) + 2P) = O(NL + P)$, y por lo tanto estaríamos cumpliendo con la complejidad pedida por el enunciado.

Formalizando un poco la idea, si tenemos una instancia de parámetros $N$ y $L$, con portales $\{(x_i, y_i)\}_{1 \leq i \leq P}$, entonces el grafo que debemos generar es $G = (V, E)$ donde $V = \{(n, i) : n \in \{1, .., N\}, i \in \{1, .., L\}\} \cup \{P_k : k \in \{1, .., P\}\}$ y 

% TODO: Grafico grafo con pesos

%TODO: grafico grafo posta

Con esto logramos transformar el "peso" de las aristas en longitud, ya que, en el nuevo grafo, viajar de $x$ a $y$ va a llevar $2$ pasos. Luego utilizamos el algoritmo de $Breadth$-$first$-$search$, sin ninguna modificación, desde el nodo que representa a la primera posición del primer piso, y deteniendo el algoritmo cuando se llegue al nodo que representa a la ultima posición del ultimo piso, una vez aquí ya sabemos que tenemos el camino mas corto en longitud desde la entrada hasta el aula de Algo 3.

\subsection{Correctitud}
Para demostrar que nuestra solución es correcta hay que demostrar que el camino generado, 

\subsection{Complejidad}



\begin{figure}[h!]
\centering
\includegraphics[width=10cm]{ex2}
\caption{El estadístico que tomamos es la media alfa podada de 100 corridas con $\alpha = 0.10$, que nos permite evitar algunos outliers. En ambos casos estamos graficando a las funciones sobre las complejidades esperadas. Nos vimos forzados a borrar algunos puntos en el worst case en un entorno del 15, ya que la computadora se colgó por otros programas y los tiempos resultaron ser outliers.\label{grf:ex2}}
\end{figure}

\pagebreak

\section{Problema 3}

\subsection{Resolución}

La resolución del tercer ejercicio depende básicamente de darse cuenta de las pistas que nos da el enunciado: dado el modelo del problema que nos determina el enunciado, el requerimiento de que no haya ciclos en el grafo de salida se traduce literalmente en que el mismo sea un árbol. Más todavía, el requerimiento de que la diferencia de la suma sea mínima se traduce literalmente en la idea intuitiva de buscar el árbol que más distancia cubra en total, minimizando la cantidad de metros de pasillos a cerrar (y por lo tanto minimizando el costo de cerrarlos).

Como vimos en clase, el concepto análogo pero minimizando la distancia es el del árbol generador mínimo, y ya conocemos los algoritmos de Kruskal y de Prim para encontrarlo; por lo tanto, supusimos que probablemente sea posible modificar los algoritmos que ya conocíamos para resolver el nuevo problema de forma eficiente.

\begin{lemma}
Sea $G = (V, E)$ un grafo conexo con pesos en los ejes determinados por $p : E \to \mathbb{R}$. Un árbol generador mínimo con función de pesos $q : E \to \mathbb{R} / q(e) = -p(e)$ es un árbol generador máximo con función de pesos $p$.
\label{pr:agm}
\end{lemma}

\begin{proof}
Sean $T = (V, E_T)$ un árbol generador mínimo con respecto a $q$ y $R = (V, E_R)$ un árbol generador. Tenemos, entonces, que

\begin{align*}
\sum_{e \in E_T} q(e) &\leq \sum_{e \in E_R} q(e)\\
\sum_{e \in E_T} -p(e) &\leq \sum_{e \in E_R} -p(e)\\
-\sum_{e \in E_T} p(e) &\leq -\sum_{e \in E_R} p(e)\\
\sum_{e \in E_T} p(e) &\geq \sum_{e \in E_R} p(e)
\end{align*}

Es decir, negar los pesos de $T$ nos da un árbol generador máximo de $G$ con respecto a la función de pesos $p$.
\end{proof}

Observemos, entonces, que transformar pesos y correr Kruskal es una manera correcta de computar el árbol generador máximo de $G$, ya que Kruskal es correcto (por lo visto en la teórica) y el lema \ref{pr:agm} nos garantiza que hacer la traducción descripta es correcto. Además, realizar la traducción es una operación relativamente barata, en tanto que pasar por todas las aristas y cambiar los pesos es una operación que toma $\Theta(m)$, mientras que Kruskal toma $O(m log(m))$ si utilizamos un disjoint set como vimos en el taller, por lo que no nos cambia la complejidad asintótica. La versión del algorítmo de Kruskal utilizada está retratada en el algoritmo \ref{alg:kruskal}; el código para hacer la transformación de los pesos de las aristas no está incluido ya que se realiza en la etapa de entrada y salida (de cualquier forma, como dijimos antes, no cambiarían ni la complejidad asintótica ni la correctitud del algoritmo incluirlo en el mismo).

\begin{algorithm}[h!]
\caption{Algoritmo de Kruskal para árbol generador mínimo. $m$ es la cantidad de aristas en el grafo. \label{alg:kruskal}}

\begin{algorithmic}[h!]
\Procedure{Kruskal}{$G$ grafo, $p$ función de pesos}
\State queue $\gets$ MIN-HEAPIFY($G.E$, $p$) \Comment $O(m)$
\State set $\gets$ Disjoint set con $|G.V|$ elementos \Comment $O(1)$
\State E $\gets \{\}$ \Comment $O(1)$

\While{$|E| < |G.V| - 1$} \Comment $O(m log(m))$
\State current $\gets$ queue.pop() \Comment $O(log(m))$
\State setFrom $\gets$ set.find(current.from) \Comment $O(1)$
\State setTo $\gets$ set.find(current.to) \Comment $O(1)$

\If{setFrom $\neq$ setTo} \Comment $O(1)$
\State set.merge(setFrom, setTo) \Comment $O(1)$
\State E $\gets E \cup \{($current.from$,$ current.to$)\}$ \Comment $O(1)$
\EndIf
\EndWhile
\State return E
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Experimentación}

Observemos que la transformación de los pesos de las aristas siempre toma exactamente $\Theta(m)$, ya que no nos queda otra más que recorrer todas las aristas para cambiar los pesos. Observemos, además, que en el algoritmo de Kruskal el mejor caso es en el que sólo tenemos que hacer heapify y tomar exactamente $n - 1$ aristas para completar el grafo sin encontrarnos ciclos, permitiéndonos entrar siempre dentro del if. Queda claro que esto sólo sucedería si el grafo fuese acíclico y tuviese exactamente $n - 1$ aristas, es decir, fuese un árbol. En este caso, tendríamos que $m \in O(n)$, y por lo tanto la complejidad temporal sería de $O(n log(n))$.

%% TODO: ejemplo de peor y mejor caso

Por otro lado, caracterizar el peor caso es más difícil: si bien es claro que el grafo debería ser denso (teniendo entonces que ya el pre-procesamiento tomaría $\Theta(n^2)$), lo ideal sería también forzar al algoritmo de Kruskal a tener que hacer pop para todas las aristas antes de poder terminar. Observemos que el algoritmo va a hacer pop hasta que haya logrado completar un árbol, por lo que la condición fundamental para que esto suceda es que las aristas que le permitan completar un árbol sean las últimas en ser procesadas. Cabe destacar entonces que el pre-procesamiento lo que hace es dar vuelta el orden de recorrido de las aristas, por lo que las aristas que fuesen las primeras al ordenarlas en el grafo original van a ser las últimas en el grafo procesado; implicando que las aristas que para completar el árbol deberían ser las de menor peso del grafo. Finalmente, para generar un grafo de $n$ nodos con estas características lo único que debemos hacer es tomar $K_n$, asignar los pesos de cualquier forma (pero siempre mayores o iguales a un número $M > 1$), y luego tomar algún nodo arbitrario del grafo, y hacer que todas sus aristas tengan peso $M - 1$. Nótese, sin embargo, que jamás será posible popear exactamente todas las aristas, ya que al llegar a la primera de las que conectan al nodo, simplemente tomaremos a esa (y no va a haber una asignación de pesos particular que logre que esto cambie). En este caso, tendríamos que $m \in O(n^2)$, por lo que la complejidad temporal pasaría a ser $O(n^2 log(n))$.

Como puede verse en la figura \ref{grf:ex3}, tenemos que ambos casos parecerían efectivamente estar en la complejidad deseada. Al igual que en los otros ejercicios, tenemos una variación muy amplia en la medición de tiempos al principio, pero terminan convergiendo a una constante, lo que demuestra que efectivamente la complejidad es como anunciamos anteriormente.

\begin{figure}[h!]
\centering
\includegraphics[width=10cm]{ex3}
\caption{El estadístico que tomamos es la media alfa podada de 100 corridas con $\alpha = 0.10$, que nos permite evitar algunos outliers. En ambos casos estamos graficando a las funciones sobre las complejidades esperadas.\label{grf:ex3}}
\end{figure}

\pagebreak

\section{Código fuente}

\subsection{Main}
%\lstinputlisting[language=C++]{../src/main.cpp}

\subsection{Ejercicio 1}
%\lstinputlisting[language=C++]{../src/Exercise1.h}
%\lstinputlisting[language=C++]{../src/Exercise1.cpp}

\subsection{Ejercicio 2}
%\lstinputlisting[language=C++]{../src/Exercise2.h}
%\lstinputlisting[language=C++]{../src/Exercise2.cpp}

\subsection{Ejercicio 3}
%\lstinputlisting[language=C++]{../src/Exercise3.h}
%\lstinputlisting[language=C++]{../src/Exercise3.cpp}

\end{document}